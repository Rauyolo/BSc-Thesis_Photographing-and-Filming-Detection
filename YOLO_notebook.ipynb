{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Pillow\n",
    "!pip install pandas\n",
    "!pip install opencv-python\n",
    "# make sure you have correct cuda and cudnn versions installed. refer to https://pytorch.org/get-started/locally/ and NVIDIA installation of cuda and cudnn\n",
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "!pip install tqdm\n",
    "!pip install matplotlib\n",
    "!pip install torch-summary\n",
    "!git clone https://github.com/EscVM/OIDv4_ToolKit.git\n",
    "!pip install -r OIDv4_ToolKit/requirements.txt\n",
    "!pip install onnx-simplifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1 Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 Choose a model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Yolo_FastestV2_V3_custom_phone_only'    # note: do not use dash (minus sign) in the name of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.2 Choose object classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enter objects you would like your model to detect. 600 are available and visible at OID/csv_folder/class-descriptions-boxable.csv \n",
    "classes = ['Camera', 'Mobile phone']\n",
    "# set to true if mobile phone and camera should be considered as one camera class. else false\n",
    "cam_and_phone_combined = True\n",
    "# set to true to use custom labelled mobile phone and camera set. make sure that it is in \"custom_dataset\" folder and in the same directory as this notebook\n",
    "custom_dataset = True\n",
    "# Enter number of images you want (if you want) to download for each object. Keep them in the same order. else simply ignore\n",
    "limit_images_to = [5000, 5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import math\n",
    "import shutil\n",
    "import os \n",
    "import PIL\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import sys\n",
    "import random\n",
    "import string\n",
    "import glob\n",
    "import pickle\n",
    "import xml.etree.ElementTree as ET\n",
    "from random import randint\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, './Yolo-FastestV2-main')\n",
    "import model.detector as det\n",
    "import utils.utils "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "'DATASET_DIR': os.path.join('OID', 'Dataset', 'train'),\n",
    "'YOLO_MAIN_DIR': os.path.join('Yolo-FastestV2-main'),\n",
    "'TRAIN_IMAGES_DEST': os.path.join('Yolo-FastestV2-main', 'train'),\n",
    "'VAL_IMAGES_DEST': os.path.join('Yolo-FastestV2-main', 'val'),\n",
    "'YOLO_DATA_DIR': os.path.join('Yolo-FastestV2-main', 'data')\n",
    "}\n",
    "\n",
    "for aClass in classes:\n",
    "    paths['DATASET_' + aClass.upper().replace(' ', '_')] = os.path.join(paths['DATASET_DIR'], aClass)\n",
    "    paths['ALL_IMGS_' + aClass.upper().replace(' ', '_')] = os.path.join(paths['DATASET_DIR'], aClass, aClass.replace(' ', '_') +'_images')\n",
    "    paths['ALL_UPDATED_LABELS_' + aClass.upper().replace(' ', '_')] = os.path.join(paths['DATASET_DIR'], aClass, 'Label_updated')\n",
    "    paths['LOCAL_TRAIN_IMGS_' + aClass.upper().replace(' ', '_')] = os.path.join(paths['DATASET_DIR'], aClass, 'train_imgs_local')\n",
    "    paths['LOCAL_TRAIN_LABELS_' + aClass.upper().replace(' ', '_')] = os.path.join(paths['DATASET_DIR'], aClass, 'train_labels_local')\n",
    "    paths['LOCAL_VAL_IMGS_' + aClass.upper().replace(' ', '_')] = os.path.join(paths['DATASET_DIR'], aClass, 'val_imgs_local')\n",
    "    paths['LOCAL_VAL_LABELS_' + aClass.upper().replace(' ', '_')] = os.path.join(paths['DATASET_DIR'], aClass, 'val_labels_local')\n",
    "    paths['YOLO_LABELS_' + aClass.upper().replace(' ', '_')] = os.path.join(paths['DATASET_DIR'], aClass, 'Yolo_format_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Labeled dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Copy command(s) below and run in the terminal. Make sure to be in the directory where this notebook is.\\n')\n",
    "\n",
    "for classNum in range(len(classes)):\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    command = ('python OIDv4_ToolKit/main.py downloader --classes ' + '\\\"' + classes[classNum] + '\\\"' + ' --type_csv train --limit ' + str(limit_images_to[classNum]))\n",
    "    print(command)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.2 Creating label files with multiple objects in an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parts of this section were mode by modifying https://github.com/EscVM/OIDv4_ToolKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv files containing labels and classes\n",
    "df_val = pd.read_csv(os.path.join('OID', 'csv_folder', 'train-annotations-bbox.csv'))\n",
    "df_classes = pd.read_csv(os.path.join('OID', 'csv_folder', 'class-descriptions-boxable.csv'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_code = [0] * len(classes)\n",
    "for classNum in range(len(classes)):\n",
    "    class_code[classNum] = df_classes.loc[df_classes[1] == classes[classNum]].values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of images needed for labelling\n",
    "groups_dict = {}\n",
    "keys = ['0'] * len(classes)\n",
    "for i in range(len(classes)):\n",
    "    keys[i] = 'groups_' + classes[i]\n",
    "\n",
    "values = class_code\n",
    "for i in range(len(keys)):\n",
    "        groups_dict[keys[i]] = df_val[(df_val.LabelName == values[i])].groupby(df_val.ImageID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put images in one folder for a clean directory structure\n",
    "for aClass in classes:\n",
    "    # remove label folder since updated version will be made\n",
    "    if os.path.exists(os.path.join(paths['DATASET_' + aClass.upper().replace(' ', '_')], 'Label')):\n",
    "        shutil.rmtree(os.path.join(paths['DATASET_' + aClass.upper().replace(' ', '_')], 'Label'))\n",
    "    !cd {os.path.join(paths['DATASET_' + aClass.upper().replace(' ', '_')])} && mkdir {aClass.replace(' ', '_')  + '_images'}\n",
    "    image_list = [f.split('.')[0] for f in os.listdir(os.path.join(paths['DATASET_DIR'], aClass)) if f.endswith('.jpg')]\n",
    "    for image in image_list:\n",
    "        os.rename(os.path.join(paths['DATASET_' + aClass.upper().replace(' ', '_')], image + '.jpg'), os.path.join(paths['ALL_IMGS_' + aClass.upper().replace(' ', '_')], image + '.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels for downloaded classes. by default when label files are made by OIDv4_ToolKit it only has one class in them.\n",
    "# this function takes care of that and can make multiple labels of different classes in an image of interest.\n",
    "def labelUpdater(): \n",
    "    groups = list(groups_dict.values())\n",
    "    for i in range(len(groups)):\n",
    "        # copies are made to not affect original lists when reshuffling entries in them\n",
    "        copy_groups = list.copy(groups)\n",
    "        copy_groups.insert(0, copy_groups.pop(copy_groups.index(copy_groups[i])))\n",
    "        copy_classes = list.copy(classes)\n",
    "        copy_classes.insert(0, copy_classes.pop(copy_classes.index(copy_classes[i])))\n",
    "\n",
    "        downloaded_images_list = [f.split('.')[0] for f in os.listdir(os.path.join(paths['ALL_IMGS_' + copy_classes[0].upper().replace(' ', '_')])) if f.endswith('.jpg')]\n",
    "        images_label_list = list(set(downloaded_images_list))\n",
    "\n",
    "        for image in tqdm(downloaded_images_list):\n",
    "            try:\n",
    "                current_image_path = os.path.join(paths['ALL_IMGS_' + copy_classes[0].upper().replace(' ', '_')], image + '.jpg')\n",
    "                dataset_image = cv2.imread(current_image_path)\n",
    "                # get boxes for current image\n",
    "                boxes = copy_groups[0].get_group(image.split('.')[0])[['XMin', 'XMax', 'YMin', 'YMax']].values.tolist()\n",
    "                file_name = str(image.split('.')[0]) + '.txt'\n",
    "                file_path = os.path.join(paths['ALL_UPDATED_LABELS_' + copy_classes[0].upper().replace(' ', '_')], file_name)\n",
    "                if os.path.isfile(file_path):\n",
    "                    f = open(file_path, 'a')\n",
    "                else:\n",
    "                    f = open(file_path, 'w')\n",
    "\n",
    "                for box in boxes:\n",
    "                    box[0] *= int(dataset_image.shape[1])\n",
    "                    box[1] *= int(dataset_image.shape[1])\n",
    "                    box[2] *= int(dataset_image.shape[0])\n",
    "                    box[3] *= int(dataset_image.shape[0])\n",
    "\n",
    "                    # each row in a file is name of the class_name, XMin, YMix, XMax, YMax (left top right bottom)\n",
    "                    print(copy_classes[0].replace(' ', '_'), box[0], box[2], box[1], box[3], file=f)\n",
    "\n",
    "                # add boxes from other classes to the label file\n",
    "                for categoryNum in range(len(copy_classes) - 1):\n",
    "                    try:\n",
    "                        boxes = copy_groups[categoryNum + 1].get_group(image.split('.')[0])[['XMin', 'XMax', 'YMin', 'YMax']].values.tolist()\n",
    "\n",
    "                        for box in boxes:\n",
    "                            box[0] *= int(dataset_image.shape[1])\n",
    "                            box[1] *= int(dataset_image.shape[1])\n",
    "                            box[2] *= int(dataset_image.shape[0])\n",
    "                            box[3] *= int(dataset_image.shape[0])\n",
    "\n",
    "                        # each row in a file is name of the class_name, XMin, YMix, XMax, YMax (left top right bottom)\n",
    "                        print(copy_classes[categoryNum + 1].replace(' ', '_'), box[0], box[2], box[1], box[3], file=f)\n",
    "                    except Exception as e:\n",
    "                        pass    \n",
    "\n",
    "            except Exception as e:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching labels in a file with hundreds of millions of entries, will take some time\n",
    "print('This might take a long time depending on the size of the dataset. Please wait...')\n",
    "if custom_dataset:\n",
    "    shutil.rmtree(os.path.join('OID', 'Dataset', 'train', 'Camera'))\n",
    "    !cd {os.path.join('OID', 'Dataset', 'train')} && mkdir Camera\n",
    "    shutil.copytree(os.path.join('custom_dataset', 'Camera', 'Camera_images'), os.path.join('OID', 'Dataset', 'train', 'Camera', 'Camera_images'))\n",
    "\n",
    "for aClass in classes:\n",
    "    if os.path.exists(os.path.join(paths['ALL_UPDATED_LABELS_' + aClass.upper().replace(' ', '_')])):\n",
    "        shutil.rmtree(os.path.join(paths['ALL_UPDATED_LABELS_' + aClass.upper().replace(' ', '_')]))\n",
    "    !cd {os.path.join(paths['DATASET_' + aClass.upper().replace(' ', '_')])} && mkdir Label_updated\n",
    "labelUpdater()\n",
    "\n",
    "if custom_dataset:\n",
    "    shutil.rmtree(os.path.join('OID', 'Dataset', 'train', 'Mobile phone'))\n",
    "    !cd {os.path.join('OID', 'Dataset', 'train')} && mkdir \"Mobile phone\"\n",
    "    shutil.copytree(os.path.join('custom_dataset', 'Mobile phone', 'train and val', 'Mobile_phone_images'), os.path.join('OID', 'Dataset', 'train', 'Mobile phone', 'Mobile_phone_images'))\n",
    "    shutil.copytree(os.path.join('custom_dataset', 'Mobile phone', 'train and val', 'Label_updated'), os.path.join('OID', 'Dataset', 'train', 'Mobile phone', 'Label_updated'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to True if you would like to use data augmentation\n",
    "add_data_augmentation = False\n",
    "# randomly select different augmentations methods for each image from preferred augmentation methods list (aug_params)\n",
    "randomize_augmentations = True\n",
    "# select factor by which corresponding classes will be increased with data augmentation. order should be the same as in section 1.2\n",
    "increase_class_by_factor = [3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if add_data_augmentation: \n",
    "    if len(increase_class_by_factor) != len(classes):\n",
    "        raise NameError('There should be the same number of factors as classes')\n",
    "    if (not all((factor >= 1 and factor <= 8) for factor in increase_class_by_factor)) or (not all(isinstance(factor, int) == True for factor in increase_class_by_factor)):\n",
    "        raise NameError('All factors need to be integers between 1 and 8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data augmentation methods you wish to use to True. Set at least 3 options to True.\n",
    "if add_data_augmentation:\n",
    "    mirror_flips = True\n",
    "    rotations = True\n",
    "    brightness_change = True\n",
    "    saturation_change = True\n",
    "    contrast_change = True\n",
    "    noise_gauss = True\n",
    "    noise_salt_and_pepper = True\n",
    "    \n",
    "    aug_params = [mirror_flips, rotations, brightness_change, saturation_change, contrast_change, noise_gauss, noise_salt_and_pepper]\n",
    "    \n",
    "    if sum(aug_params) < 3:\n",
    "        aug_params = []\n",
    "        raise NameError('At least 3 data augmentation parameters need to be set to true') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize data augmentation for each image\n",
    "def randomizeAugmentation(aug_factor):\n",
    "    results = []\n",
    "    \n",
    "    for i in range(aug_factor - 1):\n",
    "        while(True):\n",
    "            aug_params_local = list.copy(aug_params)\n",
    "            if randomize_augmentations:\n",
    "                for paramIndex in range(len(aug_params_local)):\n",
    "                    if aug_params_local[paramIndex]:\n",
    "                        # flip a random setting to false with 40% chance\n",
    "                        k = random.randint(0, 4)\n",
    "                        if k < 2 and sum(aug_params_local) >= 2:\n",
    "                            aug_params_local[paramIndex] = False\n",
    "            \n",
    "            if randomize_augmentations:\n",
    "                # check if this augmentation was not already used on an image before\n",
    "                if not results:\n",
    "                    results.append(aug_params_local)\n",
    "                    break\n",
    "                else:\n",
    "                    flag = False\n",
    "                    for result in results:\n",
    "                        if len(result) == sum([1 for i, j in zip(result, aug_params_local) if i == j]):\n",
    "                            flag = True\n",
    "                            break    # continue while\n",
    "                    if not flag:\n",
    "                        results.append(aug_params_local)\n",
    "                        break    # break while  \n",
    "            else: \n",
    "                results.append(aug_params_local)\n",
    "                break\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions were obtained from https://towardsdatascience.com/data-augmentation-compilation-with-python-and-opencv-b76b1cd500e0\n",
    "def colorjitter(img, cj_type):\n",
    "    '''\n",
    "    ### Different Color Jitter ###\n",
    "    img: image\n",
    "    cj_type: {b: brightness, s: saturation, c: constast}\n",
    "    '''\n",
    "    if cj_type == 'b':\n",
    "        value = np.random.choice(np.array([-40, -30, 30, 40]))\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = cv2.split(hsv)\n",
    "        if value >= 0:\n",
    "            lim = 255 - value\n",
    "            v[v > lim] = 255\n",
    "            v[v <= lim] += value\n",
    "        else:\n",
    "            lim = np.absolute(value)\n",
    "            v[v < lim] = 0\n",
    "            v[v >= lim] -= np.absolute(value)\n",
    "\n",
    "        final_hsv = cv2.merge((h, s, v))\n",
    "        img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "        return img\n",
    "    \n",
    "    elif cj_type == 's':\n",
    "        value = np.random.choice(np.array([-40, -30, 30, 40]))\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = cv2.split(hsv)\n",
    "        if value >= 0:\n",
    "            lim = 255 - value\n",
    "            s[s > lim] = 255\n",
    "            s[s <= lim] += value\n",
    "        else:\n",
    "            lim = np.absolute(value)\n",
    "            s[s < lim] = 0\n",
    "            s[s >= lim] -= np.absolute(value)\n",
    "\n",
    "        final_hsv = cv2.merge((h, s, v))\n",
    "        img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "        return img\n",
    "    \n",
    "    elif cj_type == 'c':\n",
    "        brightness = 10\n",
    "        contrast = random.randint(40, 100)\n",
    "        dummy = np.int16(img)\n",
    "        dummy = dummy * (contrast/127+1) - contrast + brightness\n",
    "        dummy = np.clip(dummy, 0, 255)\n",
    "        img = np.uint8(dummy)\n",
    "        return img\n",
    "    \n",
    "def noisy(img, noise_type):\n",
    "    '''\n",
    "    ### Adding Noise ###\n",
    "    img: image\n",
    "    cj_type: {gauss: gaussian, sp: salt & pepper}\n",
    "    '''\n",
    "    if noise_type == 'gauss':\n",
    "        image=img.copy() \n",
    "        mean=0\n",
    "        st=0.2\n",
    "        gauss = np.random.normal(mean,st,image.shape)\n",
    "        gauss = gauss.astype('uint8')\n",
    "        image = cv2.add(image,gauss)\n",
    "        return image\n",
    "    \n",
    "    elif noise_type == 'sp':\n",
    "        image=img.copy() \n",
    "        prob = 0.02\n",
    "        if len(image.shape) == 2:\n",
    "            black = 0\n",
    "            white = 255            \n",
    "        else:\n",
    "            colorspace = image.shape[2]\n",
    "            if colorspace == 3:  # RGB\n",
    "                black = np.array([0, 0, 0], dtype='uint8')\n",
    "                white = np.array([255, 255, 255], dtype='uint8')\n",
    "            else:  # RGBA\n",
    "                black = np.array([0, 0, 0, 255], dtype='uint8')\n",
    "                white = np.array([255, 255, 255, 255], dtype='uint8')\n",
    "        probs = np.random.random(image.shape[:2])\n",
    "        image[probs < (prob / 2)] = black\n",
    "        image[probs > 1 - (prob / 2)] = white\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment images and labels\n",
    "def augmentFunction(augmentation, index, aClass, imageName):\n",
    "    image = cv2.imread(os.path.join(paths['ALL_IMGS_' + aClass.upper().replace(' ', '_')], imageName))\n",
    "\n",
    "    # initialize to values that cannot be taken\n",
    "    flip = -2\n",
    "    rotation = -2\n",
    "    \n",
    "    # perform augmentations set to true\n",
    "    if augmentation[0]:\n",
    "        flip = random.randint(-1,1)\n",
    "        image = cv2.flip(image, flip)\n",
    "    if augmentation[1]:\n",
    "        rotation = random.randint(0,2)\n",
    "        if rotation == 0:\n",
    "            image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n",
    "        elif rotation == 1:\n",
    "            image = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        else:\n",
    "            image = cv2.rotate(image, cv2.ROTATE_180)\n",
    "    if augmentation[2]:\n",
    "        image = colorjitter(image, cj_type = 'b')\n",
    "    if augmentation[3]:\n",
    "        image = colorjitter(image, cj_type = 's')      \n",
    "    if augmentation[4]:\n",
    "        image = colorjitter(image, cj_type = 'c')        \n",
    "    if augmentation[5]:\n",
    "        image = noisy(image, 'gauss')      \n",
    "    if augmentation[6]:\n",
    "        image = noisy(image, 'sp')\n",
    "            \n",
    "    # add image to the dataset\n",
    "    cv2.imwrite(os.path.join(paths['ALL_IMGS_' + aClass.upper().replace(' ', '_')], imageName.split('.')[0] + '_aug_' + str(index) + '.jpg'), image)\n",
    "\n",
    "    label_location = os.path.join(paths['ALL_UPDATED_LABELS_' + aClass.upper().replace(' ', '_')], imageName.split('.')[0] + '.txt')\n",
    "    dest_location = os.path.join(paths['ALL_UPDATED_LABELS_' + aClass.upper().replace(' ', '_')], imageName.split('.')[0] + '_aug_' + str(index) + '.txt')\n",
    "    \n",
    "    # make labels for augmented images and take care of boxes that need to be moved due to rotations and flips\n",
    "    if (flip == -2 and rotation == -2) or (flip == -1 and rotation == 2):\n",
    "        shutil.copyfile(label_location, dest_location)\n",
    "    else:\n",
    "        with open(label_location, 'r') as fRead:\n",
    "            with open(dest_location, 'a') as fWrite:\n",
    "                imagePIL = PIL.Image.open(os.path.join(paths['ALL_IMGS_' + aClass.upper().replace(' ', '_')], imageName))\n",
    "                w, h = imagePIL.size\n",
    "                lines = fRead.readlines()\n",
    "                for line in lines:\n",
    "                    line_split = line.strip().split(' ')\n",
    "                    # x1 is line_split[1]\n",
    "                    # x2 is line_split[3]\n",
    "                    # y1 is line_split[2]\n",
    "                    # y2 is line_split[4]\n",
    "                    # w-x1 is str(w-float(line_split[1]))\n",
    "                    # w-x2 is str(w-float(line_split[3]))\n",
    "                    # h-y1 is str(h-float(line_split[2]))\n",
    "                    # h-y2 is str(h-float(line_split[4]))\n",
    "                    if (flip == -2 and rotation == 0) or (flip == -1 and rotation == 1):      \n",
    "                        # h-y2    x1    h-y1    x2        \n",
    "                        fWrite.writelines(line_split[0] + ' ' + str(h-float(line_split[4])) + ' ' + line_split[1] + ' ' + str(h-float(line_split[2])) + ' ' + line_split[3])\n",
    "                    elif (flip == -2 and rotation == 1) or (flip == -1 and rotation == 0):\n",
    "                        # y1    w-x2    y2    w-x1\n",
    "                        fWrite.writelines(line_split[0] + ' ' + line_split[2] + ' ' + str(w-float(line_split[3])) + ' ' + line_split[4]  + ' ' + str(w-float(line_split[1])))\n",
    "                    elif (flip == -2 and rotation == 2) or (flip == -1 and rotation == -2):  \n",
    "                        # w-x2    h-y2    w-x1    h-y1        \n",
    "                        fWrite.writelines(line_split[0] + ' ' + str(w-float(line_split[3])) + ' ' + str(h-float(line_split[4])) + ' ' + str(w-float(line_split[1]))  + ' ' + str(h-float(line_split[2])))\n",
    "                    elif (flip == 0 and rotation == -2) or (flip == 1 and rotation == 2):  \n",
    "                        # x1    h-y2    x2    h-y1\n",
    "                        fWrite.writelines(line_split[0] + ' ' + line_split[1] + ' ' + str(h-float(line_split[4])) + ' ' + line_split[3]  + ' ' + str(h-float(line_split[2])))\n",
    "                    elif (flip == 0 and rotation == 0) or (flip == 1 and rotation == 1):  \n",
    "                        # y1    x1    y2    x2   \n",
    "                        fWrite.writelines(line_split[0] + ' ' + line_split[2] + ' ' + line_split[1] + ' ' + line_split[4]  + ' ' + line_split[3])\n",
    "                    elif (flip == 0 and rotation == 1) or (flip == 1 and rotation == 0):         \n",
    "                        # h-y2    w-x2    h-y1    w-x1         \n",
    "                        fWrite.writelines(line_split[0] + ' ' + str(h-float(line_split[4])) + ' ' + str(w-float(line_split[3])) + ' ' + str(h-float(line_split[2]))  + ' ' + str(w-float(line_split[1])))\n",
    "                    elif (flip == 0 and rotation == 2) or (flip == 1 and rotation == -2): \n",
    "                        # w-x2    y1    w-x1    y2 \n",
    "                        fWrite.writelines(line_split[0] + ' ' + str(w-float(line_split[3])) + ' ' + line_split[2] + ' ' + str(w-float(line_split[1]))  + ' ' + line_split[4])\n",
    "       \n",
    "                    if lines.index(line) != (len(lines) - 1):\n",
    "                        fWrite.writelines('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if add_data_augmentation:\n",
    "    # can take hours with large dataset or large augmentation factor\n",
    "    print('This will certainly take a long time and even longer if dataset is large. Please wait...')    \n",
    "    for factorIndex in range(len(increase_class_by_factor)):\n",
    "        if increase_class_by_factor[factorIndex] == 1:\n",
    "            continue\n",
    "\n",
    "        all_images = os.listdir(paths['ALL_IMGS_' + classes[factorIndex].upper().replace(' ', '_')])\n",
    "        for image in tqdm(all_images):\n",
    "            aug_param_list = randomizeAugmentation(increase_class_by_factor[factorIndex])\n",
    "    \n",
    "            count_aug = 0\n",
    "            for augmentation in aug_param_list:\n",
    "                if not randomize_augmentations:\n",
    "                    augmentFunction(augmentation, count_aug, classes[factorIndex], image)\n",
    "                    count_aug = count_aug + 1\n",
    "                else:\n",
    "                    augmentFunction(augmentation, aug_param_list.index(augmentation), classes[factorIndex], image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Small object data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds cropped and smaller in size copies of objects to the image -> better small object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_obj_data_augmentation = False \n",
    "\n",
    "# number of added small objects per image\n",
    "num_of_small_obj = 1\n",
    "# enter classes you already use and would like to augment using this method. if empty -> all classes are used\n",
    "classes_for_small_obj_data_augmentation = []\n",
    "# minumum number of pixels needed for an orginal object which will be cropped and made 1.3-2.5 times smaller (see smallObjectAugmentation function)\n",
    "min_pixel_area = 4000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if small_obj_data_augmentation:\n",
    "    for aClass in classes_for_small_obj_data_augmentation:\n",
    "        if aClass not in classes:\n",
    "            raise NameError('Class \\\"' + aClass + '\\\" given in classes_for_small_obj_data_augmentation is not used in this model (check section 1.2)') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smallObjectAugmentation(aClass):\n",
    "    img_directory = os.path.join(paths['ALL_IMGS_' + aClass.upper().replace(' ', '_')])\n",
    "    images = os.listdir(img_directory)\n",
    "\n",
    "    for image in tqdm(images):\n",
    "        ori_img = cv2.imread(os.path.join(img_directory, image))\n",
    "        label_location = os.path.join(paths['ALL_UPDATED_LABELS_' + aClass.upper().replace(' ', '_')], image.split('.')[0] + '.txt')\n",
    "\n",
    "        all_boxes = []\n",
    "        all_boxes_len = 0;\n",
    "        with open(label_location, 'r') as fRead:\n",
    "            lines = fRead.readlines()\n",
    "            for line in lines:\n",
    "                line_split = line.strip().split(' ')\n",
    "                all_boxes.append([line_split[0], int(float(line_split[1])), int(float(line_split[2])), int(float(line_split[3])), int(float(line_split[4]))])\n",
    "                all_boxes_len = len(all_boxes) \n",
    "\n",
    "        for i in range (0, num_of_small_obj):\n",
    "            obj_too_small = False\n",
    "            random_box = []\n",
    "            for count in range(0, 5):\n",
    "                random_box = random.choice(all_boxes[0:all_boxes_len])\n",
    "                # if area is more than 4000 pixels\n",
    "                if (random_box[3]-random_box[1])*(random_box[4]-random_box[2]) >= min_pixel_area:\n",
    "                    break;\n",
    "                elif count == 4:\n",
    "                    obj_too_small = True\n",
    "                    break\n",
    "\n",
    "            if obj_too_small:\n",
    "                break\n",
    "\n",
    "            crop_img = ori_img[random_box[2]:random_box[4], random_box[1]:random_box[3]]\n",
    "            # resize object by this factor\n",
    "            random_resize = round(random.uniform(1.3,2.5), 2)\n",
    "            crop_img = cv2.resize(crop_img, (int(crop_img.shape[1]/random_resize), int(crop_img.shape[0]/random_resize)))\n",
    "\n",
    "            no_space_counter = 0\n",
    "            no_space = False\n",
    "            while (True):\n",
    "                # if object was randomly placed 10 times but it always overlapped with existing objects\n",
    "                if no_space_counter > 10:\n",
    "                    no_space = True\n",
    "                    break\n",
    "\n",
    "                no_space_counter = no_space_counter + 1\n",
    "                y = random.choice([i for i in range(0,ori_img.shape[0] - crop_img.shape[0])])\n",
    "                x = random.choice([i for i in range(0,ori_img.shape[1] - crop_img.shape[1])])\n",
    "\n",
    "                all_boxes_passed = False\n",
    "                for box in all_boxes:\n",
    "                    #a.x1 > b.x2 || a.x2 < b.x1 || a.y1 > b.y2 || a.y2 < b.y1, no overlaps with other objects\n",
    "                    if x > box[3] or x+crop_img.shape[1] < box[1] or y > box[4] or y+crop_img.shape[0] < box[2]:\n",
    "                        if all_boxes.index(box) == len(all_boxes) - 1:\n",
    "                            all_boxes_passed = True\n",
    "                            all_boxes.append([box[0], x, y, x+crop_img.shape[1], y+crop_img.shape[0]])\n",
    "\n",
    "                        else:\n",
    "                            continue\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                if all_boxes_passed:\n",
    "                    break\n",
    "\n",
    "            if no_space:\n",
    "                break\n",
    "\n",
    "            ori_img[y:y+crop_img.shape[0],x:x+crop_img.shape[1]] = crop_img\n",
    "\n",
    "            cv2.imwrite(os.path.join(img_directory, image), ori_img)\n",
    "\n",
    "        with open(label_location, 'w') as fWrite:\n",
    "            pass\n",
    "        \n",
    "        # update label file\n",
    "        for box in all_boxes:\n",
    "            with open(label_location, 'a') as fWrite:\n",
    "                fWrite.writelines(box[0] + ' ' + str(box[1]) + ' ' + str(box[2]) + ' ' + str(box[3]) + ' ' + str(box[4]))\n",
    "                if all_boxes.index(box) != (len(all_boxes) - 1):\n",
    "                    fWrite.writelines('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if small_obj_data_augmentation:\n",
    "    print('This might take a long time depending on the size of the dataset. Please wait...')\n",
    "    if not classes_for_small_obj_data_augmentation:\n",
    "        for aClass in classes:\n",
    "            smallObjectAugmentation(aClass)\n",
    "    else:\n",
    "        for aClass in classes_for_small_obj_data_augmentation:\n",
    "            smallObjectAugmentation(aClass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Creating labels in YoLo-FastestV2 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert OIDv4 labels to YOLO format. From (Class, x1, y1, x2, y2) to (class_num, cx, cy, w_box, h_box)\n",
    "def YoloLabelCreator(imageDir, labelDir):    \n",
    "    file_names_images = os.listdir(imageDir)\n",
    "    file_names_labels = os.listdir(labelDir)\n",
    "    !cd {os.path.join(os.path.abspath(os.path.join(imageDir, os.pardir)))} && mkdir Yolo_format_labels\n",
    "    dest_path = os.path.join(os.path.abspath(os.path.join(imageDir, os.pardir)), 'Yolo_format_labels')\n",
    "    \n",
    "    if ('Camera' in classes) and ('Mobile phone' in classes) and cam_and_phone_combined:\n",
    "        if classes.index('Camera') > classes.index('Mobile phone'):\n",
    "            larger_index = classes.index('Camera')\n",
    "            smaller_index = classes.index('Mobile phone')\n",
    "        else:\n",
    "            larger_index = classes.index('Mobile phone')\n",
    "            smaller_index = classes.index('Camera')\n",
    "\n",
    "    for file_name_image in tqdm(file_names_images):\n",
    "        image = PIL.Image.open(os.path.join(imageDir, file_name_image))\n",
    "        width, height = image.size\n",
    "        corresponding_txt = os.path.join(labelDir, file_name_image.strip().split('.')[0] + '.txt')\n",
    "        with open(corresponding_txt, 'r') as fRead:\n",
    "            data = fRead.readlines()\n",
    "            num_obj_in_image = len(data)\n",
    "            # convert each object to new format\n",
    "            for obj in range(num_obj_in_image):\n",
    "                object_data = data[obj]\n",
    "                object_data_split = object_data.strip().split(' ')\n",
    "                object_class = object_data_split[0]\n",
    "\n",
    "                center_x_pixel_obj = float(object_data_split[1]) + (float(object_data_split[3]) - float(object_data_split[1]))/2\n",
    "                center_y_pixel_obj = float(object_data_split[2]) + (float(object_data_split[4]) - float(object_data_split[2]))/2\n",
    "                cx_yolo = round(center_x_pixel_obj/width, 4)\n",
    "                cy_yolo = round(center_y_pixel_obj/height, 4)\n",
    "\n",
    "                width_pixel_obj = float(object_data_split[3]) - float(object_data_split[1])\n",
    "                height_pixel_obj = float(object_data_split[4]) - float(object_data_split[2])\n",
    "                width_yolo = round(width_pixel_obj/width, 4)\n",
    "                height_yolo = round(height_pixel_obj/height, 4)\n",
    "\n",
    "                with open(os.path.join(dest_path , file_name_image.strip().split('.')[0]) + '.txt', 'a') as fWrite:\n",
    "                    if ('Camera' in classes) and ('Mobile phone' in classes) and cam_and_phone_combined:\n",
    "                        if classes.index(object_class.replace('_', ' ')) == larger_index:\n",
    "                            object_number = str(smaller_index)\n",
    "                        elif classes.index(object_class.replace('_', ' ')) > larger_index:\n",
    "                            object_number = str(classes.index(object_class.replace('_', ' ')) - 1)\n",
    "                        else: \n",
    "                            object_number = str(classes.index(object_class.replace('_', ' ')))\n",
    "                    else:\n",
    "                        object_number = str(classes.index(object_class.replace('_', ' ')))\n",
    "                       \n",
    "                    # write new labels to a file\n",
    "                    fWrite.writelines(object_number + ' ' + str(cx_yolo) + ' ' + str(cy_yolo) + ' ' + str(width_yolo) + ' ' + str(height_yolo))\n",
    "                    if (len(data) > 1):\n",
    "                        fWrite.writelines('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This might take a long time depending on the size of the dataset. Please wait...')\n",
    "for aClass in classes:\n",
    "    if os.path.exists(os.path.join(paths['YOLO_LABELS_' + aClass.upper().replace(' ', '_')])):\n",
    "        shutil.rmtree(os.path.join(paths['YOLO_LABELS_' + aClass.upper().replace(' ', '_')]))\n",
    "    YoloLabelCreator(os.path.join(paths['ALL_IMGS_' + aClass.upper().replace(' ', '_')]), os.path.join(paths['ALL_UPDATED_LABELS_' + aClass.upper().replace(' ', '_')]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Perform 80/20 split between training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performs random 80/20 split and moves the image and all its augmented versions to one of the sets\n",
    "def trainAndValidationSplit(imageDir, labelDir, aClass):\n",
    "    TRAIN_IMAGES_LOCAL = os.path.join(os.path.abspath(os.path.join(imageDir, os.pardir)), 'train_imgs_local')\n",
    "    VAL_IMAGES_LOCAL = os.path.join(os.path.abspath(os.path.join(imageDir, os.pardir)), 'val_imgs_local')\n",
    "    TRAIN_LABELS_LOCAL = os.path.join(os.path.abspath(os.path.join(imageDir, os.pardir)), 'train_labels_local')\n",
    "    VAL_LABELS_LOCAL = os.path.join(os.path.abspath(os.path.join(imageDir, os.pardir)), 'val_labels_local')\n",
    "    !cd {os.path.join(os.path.abspath(os.path.join(imageDir, os.pardir)))} && mkdir train_imgs_local && mkdir val_imgs_local && mkdir train_labels_local && mkdir val_labels_local\n",
    "    \n",
    "    if add_data_augmentation:\n",
    "        # list should have n number of elemenets\n",
    "        n = increase_class_by_factor[classes.index(aClass)]\n",
    "    else:\n",
    "        n = 1\n",
    "    \n",
    "    file_names_images = os.listdir(imageDir)    \n",
    "    file_names_images_aug = [file_names_images[i * n:(i + 1) * n] for i in range((len(file_names_images) + n - 1) // n )] \n",
    "\n",
    "    file_names_labels = os.listdir(labelDir)\n",
    "    file_names_labels_aug = [file_names_labels[i * n:(i + 1) * n] for i in range((len(file_names_labels) + n - 1) // n )] \n",
    "\n",
    "    for image_set_index in tqdm(range(len(file_names_images_aug))):\n",
    "        rand_int = random.randint(0, 9)\n",
    "        for i in range(n):\n",
    "            # if chosen as validation image\n",
    "            if rand_int <= 1:   \n",
    "                Path(os.path.join(imageDir, file_names_images_aug[image_set_index][i])).rename(os.path.join(VAL_IMAGES_LOCAL, file_names_images_aug[image_set_index][i]))\n",
    "                Path(os.path.join(labelDir, file_names_labels_aug[image_set_index][i])).rename(os.path.join(VAL_LABELS_LOCAL, file_names_labels_aug[image_set_index][i]))\n",
    "            # if chosen as train image\n",
    "            else:\n",
    "                Path(os.path.join(imageDir, file_names_images_aug[image_set_index][i])).rename(os.path.join(TRAIN_IMAGES_LOCAL, file_names_images_aug[image_set_index][i]))\n",
    "                Path(os.path.join(labelDir, file_names_labels_aug[image_set_index][i])).rename(os.path.join(TRAIN_LABELS_LOCAL, file_names_labels_aug[image_set_index][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This might take a long time depending on the size of the dataset. Please wait...')\n",
    "for aClass in classes:\n",
    "    trainAndValidationSplit(os.path.join(paths['ALL_IMGS_' + aClass.upper().replace(' ', '_')]), os.path.join(paths['YOLO_LABELS_' + aClass.upper().replace(' ', '_')]), aClass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Move local files to destination folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if true add images of buildings, car, people(!), etc. without labels. should be only used on datasets only with cameras and phones\n",
    "# note: if training fails with IndexError: too many indices for tensor of dimension 1, then set it to False\n",
    "add_filler_images = True\n",
    "\n",
    "if ('Person' or 'Human face') in classes and add_filler_images:\n",
    "    raise NameError('Please set add_filler_images to false in this block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "if os.path.exists(os.path.join(paths['TRAIN_IMAGES_DEST'])):\n",
    "    shutil.rmtree(os.path.join(paths['TRAIN_IMAGES_DEST']))\n",
    "if os.path.exists(os.path.join(paths['VAL_IMAGES_DEST'])):\n",
    "    shutil.rmtree(os.path.join(paths['VAL_IMAGES_DEST']))\n",
    "\n",
    "!cd {paths['YOLO_MAIN_DIR']} && mkdir train && mkdir val\n",
    "\n",
    "if add_filler_images:\n",
    "    !xcopy /Y {'\\\"' + os.path.join('custom_dataset', 'Filler_images', 'train') + '\\\"'} {paths['TRAIN_IMAGES_DEST']}\n",
    "    !xcopy /Y {'\\\"' + os.path.join('custom_dataset', 'Filler_images', 'val') + '\\\"'} {paths['VAL_IMAGES_DEST']}\n",
    "# move files\n",
    "for aClass in classes:\n",
    "    !xcopy /Y {'\\\"' + os.path.join(paths['LOCAL_TRAIN_IMGS_' + aClass.upper().replace(' ', '_')]) + '\\\"'} {paths['TRAIN_IMAGES_DEST']}\n",
    "    !xcopy /Y {'\\\"' + os.path.join(paths['LOCAL_VAL_IMGS_' + aClass.upper().replace(' ', '_')]) + '\\\"'} {paths['VAL_IMAGES_DEST']}\n",
    "    !xcopy /Y {'\\\"' + os.path.join(paths['LOCAL_TRAIN_LABELS_' + aClass.upper().replace(' ', '_')]) + '\\\"'} {paths['TRAIN_IMAGES_DEST']}\n",
    "    !xcopy /Y {'\\\"' + os.path.join(paths['LOCAL_VAL_LABELS_' + aClass.upper().replace(' ', '_')]) + '\\\"'} {paths['VAL_IMAGES_DEST']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Generate dataset path .txt files for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths['TRAIN_LIST_DEST'] = os.path.join(paths['YOLO_MAIN_DIR'], 'train.txt')\n",
    "paths['VAL_LIST_DEST'] = os.path.join(paths['YOLO_MAIN_DIR'], 'val.txt')\n",
    "\n",
    "if os.path.exists(os.path.join(paths['TRAIN_LIST_DEST'])):\n",
    "    os.remove(os.path.join(paths['TRAIN_LIST_DEST']))\n",
    "if os.path.exists(os.path.join(paths['VAL_LIST_DEST'])):\n",
    "    os.remove(os.path.join(paths['VAL_LIST_DEST']))\n",
    "\n",
    "# create empty .txt files \n",
    "with open(paths['TRAIN_LIST_DEST'], 'w'): pass\n",
    "with open(paths['VAL_LIST_DEST'], 'w'): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each image in train and validation sets, create an entry in .txt file that has the path to the image\n",
    "file_names_train = os.listdir(paths['TRAIN_IMAGES_DEST'])\n",
    "for file in file_names_train:\n",
    "    stripped = file.strip().split('.')\n",
    "    if(stripped[1] == 'jpg'):\n",
    "        with open(paths['TRAIN_LIST_DEST'], 'a') as fWrite:\n",
    "            fWrite.writelines(os.path.join(os.getcwd(), 'Yolo-FastestV2-main', 'train', file))\n",
    "            if not file == file_names_train[len(file_names_train)-1] and not file == file_names_train[len(file_names_train)-2]:\n",
    "                fWrite.writelines('\\n')\n",
    "                \n",
    "file_names_val = os.listdir(paths['VAL_IMAGES_DEST'])\n",
    "for file in file_names_val:\n",
    "    stripped = file.strip().split('.')\n",
    "    if(stripped[1] == 'jpg'):\n",
    "        with open(paths['VAL_LIST_DEST'], 'a') as fWrite:\n",
    "            fWrite.writelines(os.path.join(os.getcwd(), 'Yolo-FastestV2-main', 'val', file))\n",
    "            if not file == file_names_val[len(file_names_val)-1] and not file == file_names_val[len(file_names_val)-2]:\n",
    "                fWrite.writelines('\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Generate category.names file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a file with classes names. mobile phone is set as camera if both classes are present \n",
    "if os.path.exists(os.path.join(paths['YOLO_DATA_DIR'], 'category.names')):\n",
    "    os.remove(os.path.join(paths['YOLO_DATA_DIR'], 'category.names'))\n",
    "\n",
    "if ('Camera' in classes) and ('Mobile phone' in classes) and cam_and_phone_combined:\n",
    "    if classes.index('Camera') > classes.index('Mobile phone'):\n",
    "        larger_index = classes.index('Camera')\n",
    "        smaller_index = classes.index('Mobile phone')\n",
    "    else:\n",
    "        larger_index = classes.index('Mobile phone')\n",
    "        smaller_index = classes.index('Camera')    \n",
    "    \n",
    "with open(os.path.join(paths['YOLO_DATA_DIR'], 'category.names'), 'w') as fWrite:\n",
    "    for classNum in range(len(classes)):\n",
    "        if ('Camera' in classes) and ('Mobile phone' in classes) and cam_and_phone_combined:\n",
    "            if classes.index(classes[classNum]) == smaller_index:\n",
    "                fWrite.writelines('Camera')\n",
    "            elif classes.index(classes[classNum]) == larger_index:\n",
    "                continue\n",
    "            else:   \n",
    "                fWrite.writelines(classes[classNum])\n",
    "        else:\n",
    "            fWrite.writelines(classes[classNum])\n",
    "\n",
    "        if classNum != (len(classes) - 1):\n",
    "            fWrite.writelines('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Get anchor bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This might take a long time depending on the size of the dataset. Please wait...')\n",
    "# anchors6.txt file will be generated. make sure your dataset is large, else \"nan\" is thrown and loops indefinitely\n",
    "!cd Yolo-FastestV2-main && python genanchors.py --traintxt ./train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Set train configuration settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All parameters should be in string format\n",
    "num_epochs = '300'\n",
    "learing_rate_base = '0.001'\n",
    "# Epochs at which base learning rate will be degreased by a factor of 5. E.g., steps = '150,250'\n",
    "steps = '150, 250'       \n",
    "batch_size = '128'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Build the training .data configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating configuration file that will be used by train.py script\n",
    "toWrite = []\n",
    "\n",
    "if os.path.exists(os.path.join(paths['YOLO_DATA_DIR'], model_name + '.data')):\n",
    "    os.remove(os.path.join(paths['YOLO_DATA_DIR'], model_name + '.data'))\n",
    "with open(os.path.join(paths['YOLO_DATA_DIR'], model_name + '.data'), 'w') as fWrite:\n",
    "    toWrite.append('[name]\\n')\n",
    "    toWrite.append('model_name=' + model_name + '\\n')\n",
    "    toWrite.append('\\n')\n",
    "    toWrite.append('[train-configure]\\n')\n",
    "    toWrite.append('epochs=' + num_epochs + '\\n')\n",
    "    toWrite.append('steps=' + steps + '\\n')\n",
    "    toWrite.append('batch_size=' + batch_size + '\\n')\n",
    "    toWrite.append('subdivisions=1\\n')\n",
    "    toWrite.append('learning_rate=' + learing_rate_base + '\\n')\n",
    "    toWrite.append('\\n')\n",
    "    toWrite.append('[model-configure]\\n')\n",
    "    toWrite.append('pre_weights=None\\n')\n",
    "    if ('Camera' in classes) and ('Mobile phone' in classes) and cam_and_phone_combined:\n",
    "        toWrite.append('classes=' + str(len(classes) - 1) + '\\n')\n",
    "    else: \n",
    "        toWrite.append('classes=' + str(len(classes)) + '\\n')\n",
    "    toWrite.append('width=352\\n')\n",
    "    toWrite.append('height=352\\n')\n",
    "    toWrite.append('anchor_num=3\\n')\n",
    "    with open(os.path.join(paths['YOLO_MAIN_DIR'], 'anchors6.txt'), 'r') as fRead:\n",
    "        anchors = fRead.readlines()\n",
    "        toWrite.append('anchors=' + anchors[0])\n",
    "    toWrite.append('\\n')\n",
    "    toWrite.append('[data-configure]\\n')\n",
    "    toWrite.append('train=./train.txt\\n')\n",
    "    toWrite.append('val=./val.txt\\n')\n",
    "    toWrite.append('names=./data/category.names\\n')\n",
    "\n",
    "    fWrite.writelines(toWrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(paths['YOLO_MAIN_DIR'], 'loss.txt')):\n",
    "    os.remove(os.path.join(paths['YOLO_MAIN_DIR'], 'loss.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Generate training command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = ('cd Yolo-FastestV2-main && python {} --data {} && cd ..').format('train.py', os.path.join('data', model_name + '.data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Copy the command below and run it in the terminal. Make sure to be in the directory where this notebook is.\\n')\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Plot total loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "loss = []\n",
    "\n",
    "with open(os.path.join(paths['YOLO_MAIN_DIR'], \"loss.txt\"), 'r') as fRead:\n",
    "    lines = fRead.readlines()\n",
    "    for line in lines:\n",
    "        loss.append(float(line[line.find('[')+1:line.find(']')]))\n",
    "\n",
    "plt.plot(range(1, len(loss)+1), loss)\n",
    "plt.title(\"Total loss for class \\\"Camera\\\"\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Total loss\")\n",
    "plt.xticks(np.arange(1, len(loss)+1, 20.0))\n",
    "plt.yscale('log')\n",
    "ax = plt.gca()\n",
    "plt.tick_params(axis='y', which='minor')\n",
    "ax.yaxis.set_minor_formatter(FormatStrFormatter(\"%.1f\"))\n",
    "# save figure to main directory\n",
    "plt.savefig(os.path.join(paths['YOLO_MAIN_DIR'], 'loss.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 Copy the final weight file to modelzoo directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weights_path = os.path.join(paths['YOLO_MAIN_DIR'], 'weights')\n",
    "files = os.listdir(all_weights_path)\n",
    "weight_paths = [os.path.join(all_weights_path, basename) for basename in files]\n",
    "final_weight_file = os.path.basename(max(weight_paths, key=os.path.getctime))\n",
    "!copy {os.path.join(paths['YOLO_MAIN_DIR'], 'weights', final_weight_file)} {os.path.join(paths['YOLO_MAIN_DIR'], 'modelzoo', final_weight_file)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use if you would like to choose a weight file yourself and moved it yourself to the modelzoo directory. enter the name of that weight file\n",
    "final_weight_file = 'Yolo_FastestV2_V3_custom_phone_only-290-epoch-0.814434ap-model.pth'     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates the model based on the wight file belonging to a certain epoch. prints Precision, Recall, AP, and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = ('cd Yolo-FastestV2-main && python {} --data {} --weights {}').format('evaluation.py', os.path.join('data', model_name + '.data'), os.path.join('modelzoo', final_weight_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Copy the command below and run it in the terminal. Make sure to be in the directory where this notebook is.\\n')\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 Object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from https://github.com/dog-qiuqiu/Yolo-FastestV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def passImageThroughClassifier(ori_img, cfg):\n",
    "    # Data preprocessing\n",
    "    res_img = cv2.resize(ori_img, (cfg[\"width\"], cfg[\"height\"]), interpolation = cv2.INTER_LINEAR) \n",
    "    img = res_img.reshape(1, cfg[\"height\"], cfg[\"width\"], 3)\n",
    "    img = torch.from_numpy(img.transpose(0,3, 1, 2))\n",
    "    img = img.to(device).float() / 255.0\n",
    "    \n",
    "    preds = model(img)\n",
    "\n",
    "    # Feature map post-processing\n",
    "    output = utils.utils.handel_preds(preds, cfg, device)\n",
    "    output_boxes = utils.utils.non_max_suppression(output, conf_thres = 0.3, iou_thres = 0.4)\n",
    "\n",
    "    h, w, _ = ori_img.shape\n",
    "    scale_h, scale_w = h / cfg['height'], w / cfg['width']\n",
    "    \n",
    "    return output_boxes, scale_h, scale_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "DATA_PATH = os.path.join(paths['YOLO_MAIN_DIR'], 'data', model_name + '.data')\n",
    "WEIGHTS_PATH = os.path.join(paths['YOLO_MAIN_DIR'], 'modelzoo', final_weight_file)\n",
    "opt = [DATA_PATH, WEIGHTS_PATH]\n",
    "cfg = utils.utils.load_datafile(opt[0])\n",
    "assert os.path.exists(opt[1]), 'Please specify the correct model path'\n",
    "# model loading\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = det.Detector(cfg['classes'], cfg['anchor_num'], True).to(device)\n",
    "model.load_state_dict(torch.load(opt[1], map_location=device))\n",
    "#sets the module in eval node\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LABEL_NAMES = []\n",
    "with open(os.path.join(paths['YOLO_MAIN_DIR'], 'data', 'category.names'), 'r') as f:\n",
    "    for line in f.readlines():\n",
    "         LABEL_NAMES.append(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Object detection from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from https://github.com/dog-qiuqiu/Yolo-FastestV2\n",
    "if os.path.exists(os.path.join(paths['YOLO_MAIN_DIR'], 'results', 'output_img')):\n",
    "    shutil.rmtree(os.path.join(paths['YOLO_MAIN_DIR'], 'results', 'output_img'))\n",
    "\n",
    "!mkdir {os.path.join(paths['YOLO_MAIN_DIR'], 'results', 'output_img')}\n",
    "\n",
    "images = os.listdir(os.path.join(paths['YOLO_MAIN_DIR'], 'results', 'input_img'))\n",
    "for image in images:\n",
    "    # Data preprocessing\n",
    "    ori_img = cv2.imread(os.path.join(paths['YOLO_MAIN_DIR'], 'results', 'input_img', image))\n",
    "    res_img = cv2.resize(ori_img, (cfg['width'], cfg['height']), interpolation = cv2.INTER_LINEAR) \n",
    "    img = res_img.reshape(1, cfg['height'], cfg['width'], 3)\n",
    "    img = torch.from_numpy(img.transpose(0,3, 1, 2))\n",
    "    img = img.to(device).float() / 255.0\n",
    "\n",
    "    preds = model(img)\n",
    "\n",
    "    # Feature map post-processing\n",
    "    output = utils.utils.handel_preds(preds, cfg, device)\n",
    "    output_boxes = utils.utils.non_max_suppression(output, conf_thres = 0.3, iou_thres = 0.4)\n",
    "      \n",
    "    h, w, _ = ori_img.shape\n",
    "    scale_h, scale_w = h / cfg['height'], w / cfg['width']\n",
    "\n",
    "    # Draw the prediction box\n",
    "    for box in output_boxes[0]:\n",
    "        box = box.tolist()\n",
    "\n",
    "        obj_score = box[4]\n",
    "        if obj_score > 0.6:\n",
    "            category = LABEL_NAMES[int(box[5])]\n",
    "\n",
    "            x1, y1 = int(box[0] * scale_w), int(box[1] * scale_h)\n",
    "            x2, y2 = int(box[2] * scale_w), int(box[3] * scale_h)\n",
    "\n",
    "            cv2.rectangle(ori_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(ori_img, '%.2f' % obj_score, (x1, y1 - 5), 0, 0.7, (0, 255, 0), 2)\t\n",
    "            cv2.putText(ori_img, category, (x1, y1 - 25), 0, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imwrite(os.path.join(paths['YOLO_MAIN_DIR'], 'results', 'output_img', image), ori_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 Real-time object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from https://github.com/dog-qiuqiu/Yolo-FastestV2\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while cap.isOpened(): \n",
    "    ret, ori_img = cap.read()\n",
    "    output_boxes, scale_h, scale_w = passImageThroughClassifier(ori_img, cfg)\n",
    "    \n",
    "    # Draw the prediction box\n",
    "    for box in output_boxes[0]:\n",
    "        box = box.tolist()\n",
    "\n",
    "        obj_score = box[4]\n",
    "        if obj_score > 0.5:\n",
    "            category = LABEL_NAMES[int(box[5])]\n",
    "\n",
    "            x1, y1 = int(box[0] * scale_w), int(box[1] * scale_h)\n",
    "            x2, y2 = int(box[2] * scale_w), int(box[3] * scale_h)\n",
    "            \n",
    "            cv2.rectangle(ori_img, (x1, y1), (x2, y2), (255, 255, 0), 2)\n",
    "            cv2.putText(ori_img, '%.2f' % obj_score, (x1, y1 - 5), 0, 0.7, (255, 255, 0), 2)\t\n",
    "            cv2.putText(ori_img, category, (x1, y1 - 25), 0, 0.7, (255, 255, 0), 2)\n",
    "            cv2.putText(ori_img, category, (x1, y1 - 25), 0, 0.7, (255, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('object detection',  ori_img)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "// Tencent is pleased to support the open source community by making ncnn available.  \n",
    "//  \n",
    "// Copyright (C) 2017 THL A29 Limited, a Tencent company. All rights reserved.  \n",
    "//  \n",
    "// Licensed under the BSD 3-Clause License (the \"License\"); you may not use this file except  \n",
    "// in compliance with the License. You may obtain a copy of the License at  \n",
    "//  \n",
    "// https://opensource.org/licenses/BSD-3-Clause  \n",
    "//  \n",
    "// Unless required by applicable law or agreed to in writing, software distributed  \n",
    "// under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR  \n",
    "// CONDITIONS OF ANY KIND, either express or implied. See the License for the  \n",
    "// specific language governing permissions and limitations under the License.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 Convert pytorch to onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = ('cd Yolo-FastestV2-main && python {} --data {} --weights {} --output {}').format('pytorch2onnx.py', os.path.join('data', model_name + '.data'), os.path.join('modelzoo', final_weight_file), 'yolo-fastestv2.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 onnx-simplifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = ('cd Yolo-FastestV2-main && python -m onnxsim yolo-fastestv2.onnx yolo-fastestv2-opt.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 Build NCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this section should only be run once, no need to build NCNN again for every model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd Yolo-FastestV2-main && git clone https://github.com/Tencent/ncnn.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This installation is only valid for Windows.  \n",
    "  \n",
    "At this step, Jupyter Notebook cannot be used anymore. You have to install Visual Studio 2017 with .NET framework, desktop development with c++ and Windows 10 SDK.   \n",
    "Download protobuf-3.4.0 from https://github.com/google/protobuf/archive/v3.4.0.zip and create a path variable with the location of the protobuf.  \n",
    "Download and install Vulkan SDK from https://vulkan.lunarg.com/sdk/home and make sure it is in the path. Go to start and search for x64 Native Tools Command Prompt for VS 2017 and run it as administrator (!).  \n",
    "Then build protobuf library:  \n",
    "  \n",
    "cd <protobuf-root-dir>  \n",
    "mkdir build  \n",
    "cd build  \n",
    "cmake -G\"NMake Makefiles\" -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=%cd%/install -Dprotobuf_BUILD_TESTS=OFF -Dprotobuf_MSVC_STATIC_RUNTIME=OFF ../cmake  \n",
    "nmake  \n",
    "nmake install  \n",
    "      \n",
    "And build ncnn by going to the directory of this notebook and using:  \n",
    "      \n",
    "cd Yolo-FastestV2-main  \n",
    "cd ncnn  \n",
    "mkdir build  \n",
    "cd build  \n",
    "cmake .. -G\"NMake Makefiles\"  \n",
    "nmake  \n",
    "nmake install  \n",
    "  \n",
    "If everything went well, you should see 'install' folder in ncnn/build directory.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy bin, include and lib from install folder to sample/ncnn folder\n",
    "if os.path.exists(os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'install')):\n",
    "    shutil.copytree(os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'install', 'bin'), os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'bin'))\n",
    "    shutil.copytree(os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'install', 'include'), os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'include'))\n",
    "    shutil.copytree(os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'install', 'lib'), os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'lib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.4 Conversion to NCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy yolo-fastestv2-opt.onnx in main directory to ncnn/build/tools/onnx\n",
    "if os.path.exists(os.path.join(paths['YOLO_MAIN_DIR'], 'yolo-fastestv2-opt.onnx')):\n",
    "    !copy {os.path.join(paths['YOLO_MAIN_DIR'], 'yolo-fastestv2-opt.onnx')} {os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'onnx', 'yolo-fastestv2-opt.onnx')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute onnx2ncnn file in ncnn/build/tools/onnx and generate yolo-fastestv2.bin and yolo-fastestv2.param\n",
    "!cd Yolo-FastestV2-main/ncnn/build/tools/onnx && onnx2ncnn yolo-fastestv2-opt.onnx yolo-fastestv2.param yolo-fastestv2.bin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy all yolo-fastestv2* files to parent directory (tools)\n",
    "!copy {os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'onnx', 'yolo-fastestv2-opt.onnx')} {os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'yolo-fastestv2-opt.onnx')}\n",
    "!copy {os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'onnx', 'yolo-fastestv2.bin')} {os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'yolo-fastestv2.bin')}\n",
    "!copy {os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'onnx', 'yolo-fastestv2.param')} {os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'yolo-fastestv2.param')}\n",
    "os.remove(os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'onnx', 'yolo-fastestv2-opt.onnx'))\n",
    "os.remove(os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'onnx', 'yolo-fastestv2.bin'))\n",
    "os.remove(os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'onnx', 'yolo-fastestv2.param'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute ncnnoptimize on yolo-fastestv2.param and yolo-fastestv2.bin\n",
    "!cd Yolo-FastestV2-main/ncnn/build/tools/ && ncnnoptimize yolo-fastestv2.param yolo-fastestv2.bin yolo-fastestv2-opt.param yolo-fastestv2-opt.bin 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy generated optimized yolo-fastestv2-opt* files to sample/ncnn/model folder\n",
    "!copy {os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'yolo-fastestv2-opt.bin')} {os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'model', 'yolo-fastestv2-opt.bin')}\n",
    "!copy {os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'yolo-fastestv2-opt.param')} {os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'model', 'yolo-fastestv2-opt.param')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy onnx file too\n",
    "!copy {os.path.join(paths['YOLO_MAIN_DIR'], 'yolo-fastestv2-opt.onnx')} {os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'model', 'yolo-fastestv2-opt.onnx')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.5 Quantize NCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy generated optimized yolo-fastestv2-opt* files to quantize folder folder\n",
    "!copy {os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'yolo-fastestv2-opt.bin')} {os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'quantize', 'yolo-fastestv2-opt.bin')}\n",
    "!copy {os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'yolo-fastestv2-opt.param')} {os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'quantize', 'yolo-fastestv2-opt.param')}\n",
    "os.remove(os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'yolo-fastestv2-opt.onnx'))\n",
    "os.remove(os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'yolo-fastestv2.bin'))\n",
    "os.remove(os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'yolo-fastestv2.param'))\n",
    "os.remove(os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'yolo-fastestv2-opt.bin'))\n",
    "os.remove(os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'yolo-fastestv2-opt.param'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download 1000 ImageNet images  for calibration of table file\n",
    "!cd {os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'quantize')} && git clone https://github.com/EliSchwartz/imagenet-sample-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = os.listdir(os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'quantize', 'imagenet-sample-images'))\n",
    "# remove README file\n",
    "if file_names[len(file_names) - 1] == 'README.md':\n",
    "    os.remove(os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'quantize', 'imagenet-sample-images', file_names[len(file_names) - 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create imagelist.txt file\n",
    "with open(os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'quantize', 'imagelist.txt'), 'w') as fWrite:\n",
    "    for file in file_names:\n",
    "        if file == '.git':\n",
    "            continue\n",
    "        fWrite.writelines('imagenet-sample-images/')\n",
    "        fWrite.writelines(file)\n",
    "        if file != file_names[len(file_names) - 1]:\n",
    "            fWrite.writelines('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the calibration table file\n",
    "!cd Yolo-FastestV2-main/ncnn/build/tools/quantize/ && ncnn2table yolo-fastestv2-opt.param yolo-fastestv2-opt.bin imagelist.txt yolo-fastestv2-opt.table mean=[0,0,0] norm=[0.0039,0.0039,0.0039] shape=[352,352,3] pixel=RGB thread=8 method=kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantize model\n",
    "!cd Yolo-FastestV2-main/ncnn/build/tools/quantize/ && ncnn2int8 yolo-fastestv2-opt.param yolo-fastestv2-opt.bin yolo-fastestv2-int8.param yolo-fastestv2-int8.bin yolo-fastestv2-opt.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy generated yolo-fastestv2-int8* files to sample/ncnn/model folder\n",
    "!copy {os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'quantize', 'yolo-fastestv2-int8.bin')} {os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'model', 'yolo-fastestv2-int8.bin')}\n",
    "!copy {os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'quantize', 'yolo-fastestv2-int8.param')} {os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'model', 'yolo-fastestv2-int8.param')}\n",
    "os.remove(os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'quantize', 'yolo-fastestv2-int8.bin'))\n",
    "os.remove(os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'quantize', 'yolo-fastestv2-int8.param'))\n",
    "os.remove(os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'quantize', 'yolo-fastestv2-opt.bin'))\n",
    "os.remove(os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'quantize', 'yolo-fastestv2-opt.param'))\n",
    "os.remove(os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'quantize', 'yolo-fastestv2-opt.table'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the calibration folder with images\n",
    "#if os.path.exists(os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'quantize', 'imagenet-sample-images')):\n",
    "#    os.system('rmdir /S /Q \"{}\"'.format(os.path.join(paths['YOLO_MAIN_DIR'], 'ncnn', 'build', 'tools', 'quantize', 'imagenet-sample-images')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at this step files in sample/ncnn/model folder can be copied and sent to Pi to be used. MNN is made on Pi, so onnx file will be needed for it. Pi has instructions on how to make MNN model from onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.6 Test NCNN on Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disclaimer: this section and next one are made for NCNN to run on windows. the image of the Pi already contains NCNN that can be run on Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Instructions below are there to test custom models from scratch on NCNN on Windows. Yolo-FastestV2-main\\sample\\ directory already contains codes for detection of humans and cameras (see YoLo-FastestV2-cpp-TEST and YoLo-FastestV2-cpp-REAL-TIME).\n",
    "If you would like to test other classes, demo files need to be altered accordingly. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "At this stage more efficient C++ implementation will be tested. Download OpenCV here https://opencv.org/releases/ and install it in a directory of your choice. \n",
    "Next, create a Visual Studio project (2017 was used) named YoLo-FastestV2-cpp-TEST. Place this project inside sample directory (\"Yolo-FastestV2-main\\sample\\YoLo-FastestV2-cpp-TEST\"). \n",
    "Create a blank project. Run the next cell.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy latest model files to NCNN image object detection folder\n",
    "if not os.path.exists(os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'YoLo-FastestV2-cpp-TEST' , 'model')):\n",
    "    shutil.copytree(os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'model'), os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'YoLo-FastestV2-cpp-TEST' , 'model'))\n",
    "if not os.path.exists(os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'YoLo-FastestV2-cpp-TEST' , 'src')):\n",
    "    shutil.copytree(os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'src'), os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'YoLo-FastestV2-cpp-TEST' , 'src'))\n",
    "if not os.path.exists(os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'YoLo-FastestV2-cpp-TEST' , 'demo.cpp')):\n",
    "    !copy {os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'demo.cpp')} {os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'YoLo-FastestV2-cpp-TEST' , 'demo.cpp')}\n",
    "if not os.path.exists(os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'YoLo-FastestV2-cpp-TEST' , 'test.jpg')):\n",
    "    !copy {os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'test.jpg')} {os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'YoLo-FastestV2-cpp-TEST' , 'test.jpg')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Once a blank project was created, set it to Release x64 (left of run button) and go to View -> Property Manager. \n",
    "Select Release | x64 and a window will open. Go to Common Properties -> VC++ Directories -> Include Directories and add:\n",
    "\n",
    "<your project path>/Yolo-FastestV2-main/ncnn/build/install/include/ncnn;\n",
    "<your openCV path>/opencv/build/include;\n",
    "<your openCV path>/opencv/build/include/opencv;\n",
    "<your openCV path>/opencv/build/include/opencv2;\n",
    "<your protobuf path>/protobuf-3.4.0/build/install/include;\n",
    "<your project path>/YoLo-FastestV2-cpp-TEST/src/include;\n",
    "<your project path>/YoLo-FastestV2-cpp-TEST/include/ncnn;\n",
    "\n",
    "Make sure that you already built protobuf library in previuos steps. \n",
    "Next, Go to Common Properties -> VC++ Directories -> Library Directories and add:\n",
    "\n",
    "<your openCV path>/opencv/build/x64/vc15/lib;\n",
    "<your project path>/Yolo-FastestV2-main/ncnn/build/install/lib;\n",
    "<your protobuf path>/protobuf-3.4.0/build/lib;\n",
    "\n",
    "Then go to Common Properties -> Linker -> Input -> Additional Dependencies and add:\n",
    "\n",
    "ncnn.lib;\n",
    "libprotobuf.lib;\n",
    "opencv_world455.lib;\n",
    "\n",
    "Once done your folder architecture should look like this:\n",
    "\n",
    "<your project path>/Yolo-FastestV2-main/sample/ncnn/YoLo-FastestV2-cpp-TEST\n",
    "\n",
    " model \n",
    "    model bin and param files\n",
    " src\n",
    "    yolo-fastestv2.cpp\n",
    "    yolo-fastestv2.h\n",
    " demo.cpp\n",
    " test.jpg\n",
    " YoLo-FastestV2-cpp-TEST.vcxproj\n",
    " ... (rest of Visual Studio files)\n",
    "\n",
    "Run the project. output.png will be generated in ...\\sample\\ncnn\\YoLo-FastestV2-cpp-TEST directory.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.7 Real-time object detection with NCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a Visual Studio project (2017 was used) named YoLo-FastestV2-cpp-REAL-TIME. \n",
    "Place this project inside sample directory (\"Yolo-FastestV2-main\\sample\\YoLo-FastestV2-cpp-REAL-TIME\"). Create a blank project. \n",
    "Run the next cell.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy latest model files to NCNN real-time object detection folder\n",
    "if not os.path.exists(os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'YoLo-FastestV2-cpp-REAL-TIME' , 'model')):\n",
    "    shutil.copytree(os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'model'), os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'YoLo-FastestV2-cpp-REAL-TIME' , 'model'))\n",
    "if not os.path.exists(os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'YoLo-FastestV2-cpp-REAL-TIME' , 'src')):\n",
    "    shutil.copytree(os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'src'), os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'YoLo-FastestV2-cpp-REAL-TIME' , 'src'))\n",
    "if not os.path.exists(os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'YoLo-FastestV2-cpp-REAL-TIME' , 'real-time_demo.cpp')):\n",
    "    !copy {os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'real-time_demo.cpp')} {os.path.join(paths['YOLO_MAIN_DIR'], 'sample', 'ncnn', 'YoLo-FastestV2-cpp-REAL-TIME' , 'real-time_demo.cpp')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The procedure is the same as for Test NCNN section. The only difference is now demo.cpp is replaced by real-time_demo.cpp. \n",
    "By running this scrip you will have a window showing the webcam view of the device and if camera is detected in the frame, a rectangle will be drawn around it.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 Test set generation for PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same order as in section 1.2\n",
    "limit_test_images_to = [10, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Copy command(s) below and run in the terminal. Make sure to be in the directory where this notebook is.\\n')\n",
    "\n",
    "for classNum in range(len(classes)):\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    command = ('python OIDv4_ToolKit/main.py downloader --classes ' + '\\\"' + classes[classNum] + '\\\"' + ' --type_csv test --limit ' + str(limit_test_images_to[classNum]))\n",
    "    print(command)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 11.1 Creating label files with multiple objects in an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run class_code block in section 2.2 if you didn't yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(os.path.join('OID', 'csv_folder', 'test-annotations-bbox.csv'))\n",
    "df_classes = pd.read_csv(os.path.join('OID', 'csv_folder', 'class-descriptions-boxable.csv'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_dict_test = {}\n",
    "keys_test = ['0'] * len(classes)\n",
    "for i in range(len(classes)):\n",
    "    keys_test[i] = 'groups_' + classes[i]\n",
    "\n",
    "values_test = class_code\n",
    "for i in range(len(keys_test)):\n",
    "    groups_dict_test[keys_test[i]] = df_test[(df_test.LabelName == values_test[i])].groupby(df_test.ImageID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for aClass in classes:\n",
    "    paths['TEST_DIR'] = os.path.join('OID', 'Dataset', 'test')\n",
    "    paths['TEST_' + aClass.upper().replace(' ', '_')] = os.path.join(paths['TEST_DIR'], aClass)\n",
    "    paths['ALL_TEST_IMGS_' + aClass.upper().replace(' ', '_')] = os.path.join(paths['TEST_DIR'], aClass, aClass.replace(' ', '_') +'_images')\n",
    "    paths['ALL_UPDATED_TEST_LABELS_' + aClass.upper().replace(' ', '_')] = os.path.join(paths['TEST_DIR'], aClass, 'Label_updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put images in one folder for a clean directory structure\n",
    "for aClass in classes:\n",
    "    # remove label folder since updated version will be made\n",
    "    if os.path.exists(os.path.join(paths['TEST_' + aClass.upper().replace(' ', '_')], 'Label')):\n",
    "        shutil.rmtree(os.path.join(paths['TEST_' + aClass.upper().replace(' ', '_')], 'Label'))\n",
    "    !cd {os.path.join(paths['TEST_' + aClass.upper().replace(' ', '_')])} && mkdir {aClass.replace(' ', '_')  + '_images'}\n",
    "    image_list = [f.split('.')[0] for f in os.listdir(os.path.join(paths['TEST_DIR'], aClass)) if f.endswith('.jpg')]\n",
    "    for image in image_list:\n",
    "        os.rename(os.path.join(paths['TEST_' + aClass.upper().replace(' ', '_')], image + '.jpg'), os.path.join(paths['ALL_TEST_IMGS_' + aClass.upper().replace(' ', '_')], image + '.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are mobile phone and camera in one \"Camera\" class?\n",
    "combine_phone_and_camera = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slightly different for test\n",
    "def labelUpdaterTest(): \n",
    "    groups = list(groups_dict_test.values())\n",
    "    for i in range(len(groups)):\n",
    "        # copies are made to not affect original lists when reshuffling entries in them\n",
    "        copy_groups = list.copy(groups)\n",
    "        copy_groups.insert(0, copy_groups.pop(copy_groups.index(copy_groups[i])))\n",
    "        copy_classes = list.copy(classes)\n",
    "        copy_classes.insert(0, copy_classes.pop(copy_classes.index(copy_classes[i])))\n",
    "\n",
    "        downloaded_images_list = [f.split('.')[0] for f in os.listdir(os.path.join(paths['ALL_TEST_IMGS_' + copy_classes[0].upper().replace(' ', '_')])) if f.endswith('.jpg')]\n",
    "        images_label_list = list(set(downloaded_images_list))\n",
    "\n",
    "        for image in downloaded_images_list:\n",
    "            try:\n",
    "                current_image_path = os.path.join(paths['ALL_TEST_IMGS_' + copy_classes[0].upper().replace(' ', '_')], image + '.jpg')\n",
    "                dataset_image = cv2.imread(current_image_path)\n",
    "                boxes= copy_groups[0].get_group(image.split('.')[0])[['XMin', 'XMax', 'YMin', 'YMax']].values.tolist()\n",
    "                file_name = str(image.split('.')[0]) + '.txt'\n",
    "                file_path = os.path.join(paths['ALL_UPDATED_TEST_LABELS_' + copy_classes[0].upper().replace(' ', '_')], file_name)\n",
    "                if os.path.isfile(file_path):\n",
    "                    f = open(file_path, 'a')\n",
    "                else:\n",
    "                    f = open(file_path, 'w')\n",
    "\n",
    "                for box in boxes:\n",
    "                    box[0] *= int(dataset_image.shape[1])\n",
    "                    box[1] *= int(dataset_image.shape[1])\n",
    "                    box[2] *= int(dataset_image.shape[0])\n",
    "                    box[3] *= int(dataset_image.shape[0])\n",
    "\n",
    "                    # each row in a file is name of the class_name, XMin, YMix, XMax, YMax (left top right bottom)\n",
    "                    if combine_phone_and_camera and copy_classes[0] == \"Mobile phone\":\n",
    "                        print(\"Camera\", box[0], box[2], box[1], box[3], file=f)\n",
    "                    else:\n",
    "                        print(copy_classes[0].replace(' ', '_'), box[0], box[2], box[1], box[3], file=f)\n",
    "\n",
    "                for categoryNum in range(len(copy_classes) - 1):\n",
    "                    try:\n",
    "                        boxes = copy_groups[categoryNum + 1].get_group(image.split('.')[0])[['XMin', 'XMax', 'YMin', 'YMax']].values.tolist()\n",
    "\n",
    "                        for box in boxes:\n",
    "                            box[0] *= int(dataset_image.shape[1])\n",
    "                            box[1] *= int(dataset_image.shape[1])\n",
    "                            box[2] *= int(dataset_image.shape[0])\n",
    "                            box[3] *= int(dataset_image.shape[0])\n",
    "\n",
    "                        # each row in a file is name of the class_name, XMin, YMix, XMax, YMax (left top right bottom)\n",
    "                        if combine_phone_and_camera and copy_classes[categoryNum + 1] == \"Mobile phone\":\n",
    "                            print(\"Camera\", box[0], box[2], box[1], box[3], file=f)\n",
    "                        else:\n",
    "                            print(copy_classes[categoryNum + 1].replace(' ', '_'), box[0], box[2], box[1], box[3], file=f)\n",
    "                    except Exception as e:\n",
    "                        pass    \n",
    "\n",
    "            except Exception as e:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching labels in a file with hundreds of millions of entries, will take some time\n",
    "print('This might take a long time depending on the size of the dataset. Please wait...')    \n",
    "for aClass in classes:\n",
    "    if os.path.exists(os.path.join(paths['ALL_UPDATED_TEST_LABELS_' + aClass.upper().replace(' ', '_')])):\n",
    "        shutil.rmtree(os.path.join(paths['ALL_UPDATED_TEST_LABELS_' + aClass.upper().replace(' ', '_')]))\n",
    "    !cd {os.path.join(paths['TEST_' + aClass.upper().replace(' ', '_')])} && mkdir Label_updated\n",
    "labelUpdaterTest()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "3. Training and Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "YoLo-FastestV2_env",
   "language": "python",
   "name": "yolo-fastestv2_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
